{
  "torch": {
    "method": "EGGROLL (Torch)",
    "total_steps": 20480000,
    "total_samples": 20480000,
    "wall_time_s": 15.813623428344727,
    "steps_per_second": 1295085.8538398698,
    "samples_per_second": 1295085.8538398698,
    "mean_gpu_utilization": 29.275862068965516,
    "max_gpu_utilization": 40.0,
    "min_gpu_utilization": 8.0,
    "std_gpu_utilization": 6.212130615623978,
    "mean_memory_used_mb": 1366.0,
    "max_memory_used_mb": 1366.0,
    "mean_power_w": 76.11954022988505,
    "triton_used": false,
    "torch_compile_used": false,
    "notes": [
      "triton_kernels.py uses PyTorch native ops (torch.randn, torch.bmm)"
    ]
  },
  "jax": {
    "method": "EGGROLL (JAX)",
    "total_steps": 20480000,
    "total_samples": 20480000,
    "wall_time_s": 57.247061014175415,
    "steps_per_second": 357747.6229727982,
    "samples_per_second": 357747.6229727982,
    "mean_gpu_utilization": 33.10835913312693,
    "max_gpu_utilization": 50.0,
    "min_gpu_utilization": 15.0,
    "std_gpu_utilization": 8.638815032823251,
    "mean_memory_used_mb": 19748.0,
    "max_memory_used_mb": 19748.0,
    "mean_power_w": 21.583869969040247,
    "triton_used": false,
    "torch_compile_used": false,
    "notes": [
      "JAX version: 0.8.2",
      "JAX devices: [CudaDevice(id=0)]",
      "Uses XLA for GPU compilation"
    ]
  },
  "config": {
    "num_epochs": 50,
    "pop_size": 2048,
    "layer_size": 256,
    "n_layers": 3,
    "rank": 4,
    "output_dir": "benchmarks"
  }
}